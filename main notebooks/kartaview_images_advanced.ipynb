{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# project lib\n",
    "PROJECT_SRC_PATH = os.path.join( '/workspace/workspace/ufo-prediction', 'src-RCA-UFO')\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter country code (FRA, NLD, ESP) or ALL: NLD\n",
      "Directory /workspace/workspace/ufo-prediction/image_data_NLD_adv already exists.\n",
      "Loaded processed DataFrame from /workspace/workspace/ufo-prediction/demo/kartaview_key_NLD_adv.csv\n",
      "             lon        lat  age_right                      id\n",
      "0       5.287616  52.115810     1922.0  v0.1-NLD.11.26_1-23122\n",
      "1       5.624896  52.011605     1965.0    v0.1-NLD.4.18_1-1456\n",
      "2       5.988193  51.532414     1982.0   v0.1-NLD.7.45_1-24174\n",
      "3       3.906981  51.805810     2010.0  v0.1-NLD.14.25_1-12213\n",
      "4       7.039085  52.233213     1933.0   v0.1-NLD.10.14_1-4702\n",
      "...          ...        ...        ...                     ...\n",
      "844511  4.456558  51.532000     1980.0   v0.1-NLD.8.49_1-34115\n",
      "844512  5.203008  51.796783     1988.0   v0.1-NLD.4.68_1-11607\n",
      "844513  5.182171  52.372244     1993.0    v0.1-NLD.2.1_1-75764\n",
      "844514  6.034283  51.407144     1973.0    v0.1-NLD.7.36_1-2558\n",
      "844515  4.442087  51.726000        NaN                     NaN\n",
      "\n",
      "[844516 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)  # You can choose any number as your seed\n",
    "\n",
    "# Define paths for data\n",
    "path_data_NLD = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-NLD.pkl')\n",
    "path_data_FRA = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-FRA.pkl')\n",
    "path_data_ESP = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-ESP.pkl')\n",
    "processed_df_NLD = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD_adv.csv\"\n",
    "processed_df_ESP = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP_adv.csv\"\n",
    "processed_df_FRA = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA_adv.csv\"\n",
    "processed_df_ALL = \"/workspace/workspace/ufo-prediction/demo/kartaview_key.csv\"\n",
    "\n",
    "# Image directory paths\n",
    "image_dir_map = {\n",
    "    'NLD': '/workspace/workspace/ufo-prediction/image_data_NLD_adv',\n",
    "    'FRA': '/workspace/workspace/ufo-prediction/image_data_FRA_adv',\n",
    "    'ESP': '/workspace/workspace/ufo-prediction/image_data_ESP_adv',\n",
    "    'ALL': '/workspace/workspace/ufo-prediction/image_data'\n",
    "}\n",
    "\n",
    "# Ask for user input\n",
    "country_code = input(\"Enter country code (FRA, NLD, ESP) or ALL: \").upper()\n",
    "\n",
    "# Map user input to the correct path\n",
    "path_data_map = {\n",
    "    'NLD': processed_df_NLD,\n",
    "    'FRA': processed_df_FRA,\n",
    "    'ESP': processed_df_ESP,\n",
    "    'ALL': processed_df_ALL\n",
    "}\n",
    "\n",
    "raw_data_path_map = {\n",
    "'NLD': path_data_NLD,\n",
    "'FRA': path_data_FRA,\n",
    "'ESP': path_data_ESP\n",
    "}\n",
    "# Check if the input is valid\n",
    "if country_code not in path_data_map:\n",
    "    print(\"Invalid country code or specification. Please enter FRA, NLD, ESP, or ALL.\")\n",
    "else:\n",
    "    processed_df_path = path_data_map[country_code]\n",
    "    # Set directory based on country code\n",
    "    current_directory = image_dir_map[country_code]\n",
    "\n",
    "    # Check if the new directory exists, if not, create it\n",
    "    if not os.path.exists(current_directory):\n",
    "        os.makedirs(current_directory)\n",
    "        print(f\"Directory {current_directory} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {current_directory} already exists.\")\n",
    "\n",
    "    # Process for ALL\n",
    "    if country_code == 'ALL':\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(\"Creating a new processed DataFrame for ALL\")\n",
    "            path_data_RCA = os.path.join(dataset.DATA_DIR, 'rca-ufo-merge_ALL.csv')\n",
    "            df = pd.read_csv(path_data_RCA, encoding='latin1')\n",
    "            kartaview_keys = df[['lon', 'lat','age_right', 'id', 'PropertyKey_ID']]\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "            \n",
    "\n",
    "    # Process for FRA, NLD, ESP\n",
    "    else:\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(f\"Creating a new processed DataFrame for {country_code}\")\n",
    "            df_path = raw_data_path_map[country_code]\n",
    "            df = pd.read_pickle(df_path)\n",
    "            print(\"Loaded DataFrame from\", df_path)\n",
    "            sampled_df = df.sample(n=1500000, random_state=42)\n",
    "            kartaview_keys = sampled_df[['lon', 'lat', 'age', 'id']].rename(columns={'age': 'age_right'})\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "print(kartaview_keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/workspace/ufo-prediction/image_data_NLD_adv\n",
      "             lon        lat  age_right                      id\n",
      "0       5.287616  52.115810     1922.0  v0.1-NLD.11.26_1-23122\n",
      "1       5.624896  52.011605     1965.0    v0.1-NLD.4.18_1-1456\n",
      "2       5.988193  51.532414     1982.0   v0.1-NLD.7.45_1-24174\n",
      "3       3.906981  51.805810     2010.0  v0.1-NLD.14.25_1-12213\n",
      "4       7.039085  52.233213     1933.0   v0.1-NLD.10.14_1-4702\n",
      "...          ...        ...        ...                     ...\n",
      "844511  4.456558  51.532000     1980.0   v0.1-NLD.8.49_1-34115\n",
      "844512  5.203008  51.796783     1988.0   v0.1-NLD.4.68_1-11607\n",
      "844513  5.182171  52.372244     1993.0    v0.1-NLD.2.1_1-75764\n",
      "844514  6.034283  51.407144     1973.0    v0.1-NLD.7.36_1-2558\n",
      "844515  4.442087  51.726000        NaN                     NaN\n",
      "\n",
      "[844516 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(current_directory)\n",
    "print(kartaview_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be saved in: /workspace/workspace/ufo-prediction/image_data_NLD_adv\n",
      "Using kartaview_keys from: /workspace/workspace/ufo-prediction/demo/kartaview_key_NLD_adv.csv\n",
      "Inconsistency detected between the image directory and the kartaview_keys path. Please check.\n",
      "Number of buildings remaining:  844516\n",
      "No suitable images found for location: lon=5.287616, lat=52.115810\n",
      "No suitable images found for location: lon=5.28762, lat=52.11581\n",
      "No suitable images found for location: lon=5.2876, lat=52.1158\n",
      "No suitable images found for location: lon=5.288, lat=52.116\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.287616161693388, lat=52.11581011855476\n",
      "No suitable images found for location: lon=5.624896, lat=52.011605\n",
      "No suitable images found for location: lon=5.62490, lat=52.01161\n",
      "No suitable images found for location: lon=5.6249, lat=52.0116\n",
      "No suitable images found for location: lon=5.625, lat=52.012\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.624896219578538, lat=52.01160502485976\n",
      "No suitable images found for location: lon=5.988193, lat=51.532414\n",
      "No suitable images found for location: lon=5.98819, lat=51.53241\n",
      "No suitable images found for location: lon=5.9882, lat=51.5324\n",
      "No suitable images found for location: lon=5.988, lat=51.532\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.988192682475085, lat=51.53241390249917\n",
      "No suitable images found for location: lon=3.906981, lat=51.805810\n",
      "No suitable images found for location: lon=3.90698, lat=51.80581\n",
      "No suitable images found for location: lon=3.9070, lat=51.8058\n",
      "No suitable images found for location: lon=3.907, lat=51.806\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=3.9069814812601775, lat=51.80580991064805\n",
      "No suitable images found for location: lon=7.039085, lat=52.233213\n",
      "No suitable images found for location: lon=7.03909, lat=52.23321\n",
      "No suitable images found for location: lon=7.0391, lat=52.2332\n",
      "No suitable images found for location: lon=7.039, lat=52.233\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=7.039085319243373, lat=52.23321336108378\n",
      "No suitable images found for location: lon=4.903560, lat=52.080963\n",
      "No suitable images found for location: lon=4.90356, lat=52.08096\n",
      "No suitable images found for location: lon=4.9036, lat=52.0810\n",
      "No suitable images found for location: lon=4.904, lat=52.081\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.903560194378874, lat=52.08096320153915\n",
      "No suitable images found for location: lon=4.658148, lat=52.480810\n",
      "No suitable images found for location: lon=4.65815, lat=52.48081\n",
      "No suitable images found for location: lon=4.6581, lat=52.4808\n",
      "No suitable images found for location: lon=4.658, lat=52.481\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.658148494275045, lat=52.48080965341651\n",
      "No suitable images found for location: lon=4.529291, lat=51.849171\n",
      "No suitable images found for location: lon=4.52929, lat=51.84917\n",
      "No suitable images found for location: lon=4.5293, lat=51.8492\n",
      "No suitable images found for location: lon=4.529, lat=51.849\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.529290670603743, lat=51.849170627228325\n",
      "No suitable images found for location: lon=5.944083, lat=51.372176\n",
      "No suitable images found for location: lon=5.94408, lat=51.37218\n",
      "No suitable images found for location: lon=5.9441, lat=51.3722\n",
      "No suitable images found for location: lon=5.944, lat=51.372\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.944083227436459, lat=51.37217552389691\n",
      "No suitable images found for location: lon=6.401579, lat=52.156216\n",
      "No suitable images found for location: lon=6.40158, lat=52.15622\n",
      "No suitable images found for location: lon=6.4016, lat=52.1562\n",
      "No suitable images found for location: lon=6.402, lat=52.156\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.401579485803635, lat=52.15621563274921\n",
      "No suitable images found for location: lon=4.293885, lat=52.028782\n",
      "No suitable images found for location: lon=4.29389, lat=52.02878\n",
      "No suitable images found for location: lon=4.2939, lat=52.0288\n",
      "No suitable images found for location: lon=4.294, lat=52.029\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.293885313096576, lat=52.02878224856291\n",
      "No suitable images found for location: lon=7.017347, lat=53.193372\n",
      "No suitable images found for location: lon=7.01735, lat=53.19337\n",
      "No suitable images found for location: lon=7.0173, lat=53.1934\n",
      "No suitable images found for location: lon=7.017, lat=53.193\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=7.017346980464669, lat=53.19337166265676\n",
      "No suitable images found for location: lon=6.559322, lat=53.227907\n",
      "No suitable images found for location: lon=6.55932, lat=53.22791\n",
      "No suitable images found for location: lon=6.5593, lat=53.2279\n",
      "No suitable images found for location: lon=6.559, lat=53.228\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.559321680707533, lat=53.22790672979095\n",
      "No suitable images found for location: lon=4.660898, lat=51.791528\n",
      "No suitable images found for location: lon=4.66090, lat=51.79153\n"
     ]
    }
   ],
   "source": [
    "# Assuming current_directory and processed_df_path are set from the previous code chunk\n",
    "print(f\"Images will be saved in: {current_directory}\")\n",
    "print(f\"Using kartaview_keys from: {processed_df_path}\")\n",
    "\n",
    "# Consistency check between image directory and kartaview_keys path\n",
    "expected_csv_map = {\n",
    "    '/workspace/workspace/ufo-prediction/image_data': '/workspace/workspace/ufo-prediction/demo/kartaview_key.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_NLD': '/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_FRA': '/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_ESP': '/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv',\n",
    "}\n",
    "\n",
    "# Stop the code if using image_data directory\n",
    "if current_directory == '/workspace/workspace/ufo-prediction/image_data':\n",
    "    print(\"Download for the 'image_data' directory has already been completed. Stopping execution.\")\n",
    "    # Use `exit()` or `sys.exit()` depending on your environment\n",
    "    exit()\n",
    "\n",
    "if processed_df_path != expected_csv_map.get(current_directory):\n",
    "    print(\"Inconsistency detected between the image directory and the kartaview_keys path. Please check.\")\n",
    "    exit()\n",
    "\n",
    "image_count = {} \n",
    "print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "\n",
    "#Initialise a counter for the loop iterations\n",
    "iteration_counter = 0\n",
    "\n",
    "for index, row in kartaview_keys.iterrows():\n",
    "    iteration_counter += 1 # Increment the counter with each iteration\n",
    "    precision = 6  # Start with 6 decimal places\n",
    "    success = False  # Flag to indicate if the request was successful\n",
    "\n",
    "    while precision > 2 and not success:\n",
    "        # Format lon and lat to the current precision\n",
    "        lon = f\"{row['lon']:.{precision}f}\"\n",
    "        lat = f\"{row['lat']:.{precision}f}\"\n",
    "\n",
    "        # Construct the API URL\n",
    "        url = \"https://api.openstreetcam.org/2.0/photo/?lat={}&lng={}\".format(lat, lon)\n",
    "\n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            url_pattern = r'https://storage\\d+\\.openstreetcam\\.org/files/photo/\\d+/\\d+/\\d+/[^\"]+\\.jpg'\n",
    "            urls = re.findall(url_pattern, json.dumps(data))\n",
    "\n",
    "            filtered_urls = [\n",
    "                url for url in urls\n",
    "                if not any(x in url.rsplit('/', 2)[-2] for x in [\"{{sizeprefix}}\", \"proc\"]) and\n",
    "                (\"th\" in url.rsplit('/', 2)[-2] and not \"lth\" in url.rsplit('/', 2)[-2])\n",
    "            ]\n",
    "\n",
    "            if filtered_urls:\n",
    "                # Initialize or update the image count for the current ID\n",
    "                building_id = row['id']  # Assuming 'id' column exists in your DataFrame\n",
    "                if building_id not in image_count:\n",
    "                    image_count[building_id] = 0\n",
    "\n",
    "                for image_url in filtered_urls:\n",
    "                    image_count[building_id] += 1  # Increment the image count for the building\n",
    "                    subscript = image_count[building_id]  # Subscript for the file name\n",
    "                    file_name = f\"{row['age_right']}_{building_id}_{subscript}.jpg\"\n",
    "                    file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "                    # Check if the file already exists\n",
    "                    if os.path.exists(file_path):\n",
    "                        print(f\"File already exists: {file_path}. Skipping download.\")\n",
    "                    else:\n",
    "                        image_response = requests.get(image_url)\n",
    "\n",
    "                        if image_response.status_code == 200:\n",
    "                            with open(file_path, 'wb') as f:\n",
    "                                f.write(image_response.content)\n",
    "                            print(\"Image downloaded successfully: {}\".format(file_path))\n",
    "                        else:\n",
    "                            print(\"Failed to download the image.\")\n",
    "                success = True  # Mark success as True to exit the while loop\n",
    "            else:\n",
    "                print(\"No suitable images found for location: lon={}, lat={}\".format(lon, lat))\n",
    "                precision -= 1  # Reduce precision by one decimal place\n",
    "        else:\n",
    "            print(\"Failed to retrieve data from the API for location: lon={}, lat={}. Trying with reduced precision.\")\n",
    "            \n",
    "\n",
    "    # After processing, remove the row from df_subset\n",
    "    kartaview_keys = kartaview_keys.drop(index)\n",
    "\n",
    "    # Only save the updated DataFrame to a CSV file every 100th instance\n",
    "    if iteration_counter % 100 == 0:\n",
    "        print(f\"Saving progress at iteration {iteration_counter} to {processed_df_path}. \")\n",
    "        print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "        kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "    if not success:\n",
    "        print(\"Unable to retrieve data from the API with sufficient precision for location: lon={}, lat={}\".format(row['lon'], row['lat']))\n",
    "        \n",
    "if iteration_counter % 100 != 0:\n",
    "    print(f\"Saving final progress\")\n",
    "    print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "    kartaview_keys.to_csv(processed_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
