{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list =['NLD', 'FRA', 'ESP']\n",
    "country_map = {\n",
    "    'NLD': 'Netherlands',\n",
    "    'FRA': 'France',\n",
    "    'ESP': 'Spain'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_RCA = os.path.join('/workspace/workspace/ufo-prediction', 'main notebooks', 'RCA_subset.csv')\n",
    "rca_dt = pd.read_csv(path_data_RCA, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United Kingdom    24192\n",
      "Germany           22382\n",
      "France            10476\n",
      "Netherlands       10136\n",
      "Spain              3934\n",
      "Austria            3543\n",
      "Italy              2488\n",
      "Finland            1919\n",
      "Belgium            1539\n",
      "Ireland            1241\n",
      "Portugal           1027\n",
      "Luxembourg          242\n",
      "Bulgaria            212\n",
      "Greece              205\n",
      "Slovakia            194\n",
      "Croatia             175\n",
      "Estonia             112\n",
      "Lithuania            85\n",
      "Latvia               81\n",
      "Slovenia             78\n",
      "Malta                 1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merge_counts = rca_dt['country'].value_counts()\n",
    "print(merge_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geodataframe(df, lat_col, lon_col):\n",
    "    df['geometry'] = df.apply(lambda row: Point(row[lon_col], row[lat_col]), axis=1)\n",
    "    return gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Identifying match type\n",
    "def match_type(row):\n",
    "    if pd.isna(row['index_right0']):\n",
    "        return 'no match'\n",
    "    elif round(row['Lat_nb'], 5) == round(row['lat'], 5) and round(row['Lon_nb'], 5) == round(row['lon'], 5):\n",
    "        return 'exact match'\n",
    "    elif round(row['Lat_nb'], 4) == round(row['lat'], 4) and round(row['Lon_nb'], 4) == round(row['lon'], 4):\n",
    "        return 'match on 10m accuracy'\n",
    "    else:\n",
    "        return 'match on 50m accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rca = create_geodataframe(rca_dt, 'Lat_nb', 'Lon_nb')\n",
    "# Setting coordinate system (assuming WGS84)\n",
    "gdf_rca.set_crs(epsg=4326, inplace=True)\n",
    "# Transform the CRS to UTM zone 32N (EPSG:32632) so that distances are in meters\n",
    "gdf_rca_n = gdf_rca.to_crs(epsg=32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLD\n",
      "match_type\n",
      "match on 50m accuracy    3109\n",
      "no match                 2845\n",
      "age uncertainty          1772\n",
      "footprint filter         1730\n",
      "match on 10m accuracy     652\n",
      "exact match                28\n",
      "Name: count, dtype: int64\n",
      "FRA\n",
      "match_type\n",
      "no match                 7259\n",
      "footprint filter         1303\n",
      "age uncertainty          1044\n",
      "match on 50m accuracy     749\n",
      "match on 10m accuracy     116\n",
      "exact match                 5\n",
      "Name: count, dtype: int64\n",
      "ESP\n",
      "match_type\n",
      "match on 50m accuracy    1297\n",
      "no match                 1028\n",
      "footprint filter          971\n",
      "age uncertainty           453\n",
      "match on 10m accuracy     182\n",
      "exact match                 3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for ctr in country_list:\n",
    "    print(ctr)\n",
    "    # read in the data\n",
    "    df = pd.read_pickle('/workspace/workspace/ufo-prediction/main notebooks/df-'+ctr+'.pkl')\n",
    "    # drop the geometry column\n",
    "    df = df.drop(columns=['geometry'])\n",
    "    # convert to geodataframe\n",
    "    gdf_ufo = create_geodataframe(df, 'lat', 'lon')\n",
    "    # Setting coordinate system (assuming WGS84)\n",
    "    gdf_ufo.set_crs(epsg=4326, inplace=True)\n",
    "    # Transform the CRS to UTM zone 32N (EPSG:32632) so that distances are in meters\n",
    "    gdf_ufo_n = gdf_ufo.to_crs(epsg=32632)\n",
    "    # Spatial join - finds matches within 110 meters\n",
    "    matches = gpd.sjoin_nearest(gdf_rca_n, gdf_ufo_n, distance_col='distances', how='left', max_distance=110)\n",
    "    # add match type\n",
    "    matches['match_type'] = matches.apply(match_type, axis=1)\n",
    "    # Add a new column 'BldLenProxy' as the square root of 'FootprintArea'\n",
    "    matches['BldLenProxy'] = np.sqrt(matches['FootprintArea'])\n",
    "    # Set 'match_type' to 'no match' where 'BldLenProxy' is less than or equal to 'distances'\n",
    "    matches.loc[matches['BldLenProxy'] <= matches['distances'], 'match_type'] = 'footprint filter'\n",
    "    # Set 'match_type' to 'no match' where the absolute difference between 'age_right' and 'YearBlt' is more than 10 years\n",
    "    matches.loc[abs(matches['age_right'] - matches['YearBlt']) > 10, 'match_type'] = 'age uncertainty'\n",
    "    # Filter out the rows where 'match_type' is 'no match'\n",
    "    #matches = matches[matches['match_type'] != 'no match']\n",
    "    #matches = matches[matches['country_right'] == ctr]\n",
    "    matches = matches[matches['country_left'] == country_map[ctr]]\n",
    "    # rename the country column\n",
    "    matches.rename(columns={'country_left': 'country'}, inplace=True)\n",
    "    # Counting how many rows fall into each merge category\n",
    "    merge_counts = matches['match_type'].value_counts()\n",
    "    print(merge_counts)\n",
    "    # save the data\n",
    "    matches.to_csv('/workspace/workspace/ufo-prediction/main notebooks/rca-ufo-merge'+ctr+'.csv', index=False)\n",
    "    # free up memory\n",
    "    del df, gdf_ufo, gdf_ufo_n, matches, merge_counts\n",
    "    # collect garbage\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLD\n",
      "Number of rows before appending: 10136\n",
      "Columns with all NA values: ['Unnamed: 0.1', 'type_source', 'floors', 'type']\n",
      "FRA\n",
      "Number of rows before appending: 10476\n",
      "Columns with all NA values: ['Unnamed: 0.1']\n",
      "ESP\n",
      "Number of rows before appending: 3934\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "for ctr in country_list:\n",
    "    print(ctr)\n",
    "    # read in the data\n",
    "    df = pd.read_csv('/workspace/workspace/ufo-prediction/main notebooks/rca-ufo-merge'+ctr+'.csv', encoding='latin1')\n",
    "    print(f\"Number of rows before appending: {df.shape[0]}\")\n",
    "    # append country dataset to combined_df\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    # Record the number of rows after appending and before removing duplicates\n",
    "    rows_after_append = combined_df.shape[0]\n",
    "    # Remove duplicates\n",
    "    combined_df.drop_duplicates(inplace=True)\n",
    "    # Record the number of rows after removing duplicates\n",
    "    rows_after_duplicates_removed = combined_df.shape[0]\n",
    "    # Calculate and print the number of duplicates removed\n",
    "    duplicates_removed = rows_after_append - rows_after_duplicates_removed\n",
    "    if duplicates_removed > 0:\n",
    "        print(f\"Removed {duplicates_removed} duplicate rows.\")\n",
    "    # Identify columns with all NA values\n",
    "    all_na_columns = combined_df.columns[combined_df.isna().all()]\n",
    "    if not all_na_columns.empty:\n",
    "        print(\"Columns with all NA values:\", all_na_columns.tolist())\n",
    "    # free up memory\n",
    "    del df\n",
    "    # collect garbage\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLD\n",
    "Number of rows before appending: 3789\n",
    "Columns with all NA values: ['Unnamed: 0.1', 'type_source', 'floors', 'type']\n",
    "FRA\n",
    "Number of rows before appending: 870\n",
    "Columns with all NA values: ['Unnamed: 0.1']\n",
    "ESP\n",
    "Number of rows before appending: 1482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of NA values in 'residential_type': 0.00\n"
     ]
    }
   ],
   "source": [
    "if 'residential_type' in combined_df.columns:\n",
    "    na_share = combined_df['residential_type'].isna().mean()\n",
    "    print(f\"Share of NA values in 'residential_type': {na_share:.2f}\")\n",
    "else:\n",
    "    print(\"Column 'residential_type' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of NA values in 'country': 0.00\n"
     ]
    }
   ],
   "source": [
    "combined_df.rename(columns={'country_left': 'country'}, inplace=True)\n",
    "if 'country' in combined_df.columns:\n",
    "    na_share = combined_df['country'].isna().mean()\n",
    "    print(f\"Share of NA values in 'country': {na_share:.2f}\")\n",
    "else:\n",
    "    print(\"Column 'country' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('/workspace/workspace/ufo-prediction/main notebooks/rca-ufo-merge_ALL_descStata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['match_type'] != 'no match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['match_type'] != 'footprint filter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['match_type'] != 'age uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('/workspace/workspace/ufo-prediction/main notebooks/rca-ufo-merge_ALL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del combined_df, gdf_rca, gdf_rca_n, rca_dt\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
