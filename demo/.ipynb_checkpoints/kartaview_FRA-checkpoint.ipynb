{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# project lib\n",
    "PROJECT_SRC_PATH = os.path.join( '/workspace/workspace/ufo-prediction', 'src-RCA-UFO')\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter country code (FRA, NLD, ESP) or ALL: FRA\n",
      "Directory /workspace/workspace/ufo-prediction/image_data_FRA_adv already exists.\n",
      "Loaded processed DataFrame from /workspace/workspace/ufo-prediction/demo/kartaview_key_FRA_adv.csv\n",
      "              lon        lat  age_right                         id\n",
      "0        6.537046  49.324550     1992.0   v0.1-FRA.6.9.1.2_1-12979\n",
      "1        2.057612  48.238201     1983.0    v0.1-FRA.4.6.3.3_1-4131\n",
      "2        5.031798  43.702803     1992.0  v0.1-FRA.13.3.2.4_1-10256\n",
      "3        0.015972  49.261723     2008.0    v0.1-FRA.9.1.3.3_1-9014\n",
      "4        5.425173  45.570039     2003.0   v0.1-FRA.1.8.2.6_1-20139\n",
      "...           ...        ...        ...                        ...\n",
      "1273295  3.363240  49.429058     1920.0   v0.1-FRA.7.1.4.6_1-10259\n",
      "1273296 -2.968725  47.841208     1900.0  v0.1-FRA.3.4.1.10_1-11793\n",
      "1273297  5.007878  44.394222     1991.0  v0.1-FRA.13.6.2.10_1-6435\n",
      "1273298  5.714591  45.738590     1905.0    v0.1-FRA.1.1.1.2_1-9099\n",
      "1273299 -0.464786  45.030712     2001.0   v0.1-FRA.10.7.2.3_1-4370\n",
      "\n",
      "[1273300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)  # You can choose any number as your seed\n",
    "\n",
    "# Define paths for data\n",
    "path_data_NLD = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-NLD.pkl')\n",
    "path_data_FRA = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-FRA.pkl')\n",
    "path_data_ESP = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-ESP.pkl')\n",
    "processed_df_NLD = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD_adv.csv\"\n",
    "processed_df_ESP = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP_adv.csv\"\n",
    "processed_df_FRA = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA_adv.csv\"\n",
    "processed_df_ALL = \"/workspace/workspace/ufo-prediction/demo/kartaview_key.csv\"\n",
    "\n",
    "# Image directory paths\n",
    "image_dir_map = {\n",
    "    'NLD': '/workspace/workspace/ufo-prediction/image_data_NLD_adv',\n",
    "    'FRA': '/workspace/workspace/ufo-prediction/image_data_FRA_adv',\n",
    "    'ESP': '/workspace/workspace/ufo-prediction/image_data_ESP_adv',\n",
    "    'ALL': '/workspace/workspace/ufo-prediction/image_data'\n",
    "}\n",
    "\n",
    "# Ask for user input\n",
    "country_code = input(\"Enter country code (FRA, NLD, ESP) or ALL: \").upper()\n",
    "\n",
    "# Map user input to the correct path\n",
    "path_data_map = {\n",
    "    'NLD': processed_df_NLD,\n",
    "    'FRA': processed_df_FRA,\n",
    "    'ESP': processed_df_ESP,\n",
    "    'ALL': processed_df_ALL\n",
    "}\n",
    "\n",
    "raw_data_path_map = {\n",
    "'NLD': path_data_NLD,\n",
    "'FRA': path_data_FRA,\n",
    "'ESP': path_data_ESP\n",
    "}\n",
    "# Check if the input is valid\n",
    "if country_code not in path_data_map:\n",
    "    print(\"Invalid country code or specification. Please enter FRA, NLD, ESP, or ALL.\")\n",
    "else:\n",
    "    processed_df_path = path_data_map[country_code]\n",
    "    # Set directory based on country code\n",
    "    current_directory = image_dir_map[country_code]\n",
    "\n",
    "    # Check if the new directory exists, if not, create it\n",
    "    if not os.path.exists(current_directory):\n",
    "        os.makedirs(current_directory)\n",
    "        print(f\"Directory {current_directory} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {current_directory} already exists.\")\n",
    "\n",
    "    # Process for ALL\n",
    "    if country_code == 'ALL':\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(\"Creating a new processed DataFrame for ALL\")\n",
    "            path_data_RCA = os.path.join(dataset.DATA_DIR, 'rca-ufo-merge_ALL.csv')\n",
    "            df = pd.read_csv(path_data_RCA, encoding='latin1')\n",
    "            kartaview_keys = df[['lon', 'lat','age_right', 'id', 'PropertyKey_ID']]\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "            \n",
    "\n",
    "    # Process for FRA, NLD, ESP\n",
    "    else:\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(f\"Creating a new processed DataFrame for {country_code}\")\n",
    "            df_path = raw_data_path_map[country_code]\n",
    "            df = pd.read_pickle(df_path)\n",
    "            print(\"Loaded DataFrame from\", df_path)\n",
    "            sampled_df = df.sample(n=1500000, random_state=42)\n",
    "            kartaview_keys = sampled_df[['lon', 'lat', 'age', 'id']].rename(columns={'age': 'age_right'})\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "print(kartaview_keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/workspace/ufo-prediction/image_data_FRA_adv\n",
      "              lon        lat  age_right                         id\n",
      "0        6.537046  49.324550     1992.0   v0.1-FRA.6.9.1.2_1-12979\n",
      "1        2.057612  48.238201     1983.0    v0.1-FRA.4.6.3.3_1-4131\n",
      "2        5.031798  43.702803     1992.0  v0.1-FRA.13.3.2.4_1-10256\n",
      "3        0.015972  49.261723     2008.0    v0.1-FRA.9.1.3.3_1-9014\n",
      "4        5.425173  45.570039     2003.0   v0.1-FRA.1.8.2.6_1-20139\n",
      "...           ...        ...        ...                        ...\n",
      "1273295  3.363240  49.429058     1920.0   v0.1-FRA.7.1.4.6_1-10259\n",
      "1273296 -2.968725  47.841208     1900.0  v0.1-FRA.3.4.1.10_1-11793\n",
      "1273297  5.007878  44.394222     1991.0  v0.1-FRA.13.6.2.10_1-6435\n",
      "1273298  5.714591  45.738590     1905.0    v0.1-FRA.1.1.1.2_1-9099\n",
      "1273299 -0.464786  45.030712     2001.0   v0.1-FRA.10.7.2.3_1-4370\n",
      "\n",
      "[1273300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(current_directory)\n",
    "print(kartaview_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be saved in: /workspace/workspace/ufo-prediction/image_data_FRA_adv\n",
      "Using kartaview_keys from: /workspace/workspace/ufo-prediction/demo/kartaview_key_FRA_adv.csv\n",
      "Inconsistency detected between the image directory and the kartaview_keys path. Please check.\n",
      "Number of buildings remaining:  1273300\n",
      "No suitable images found for location: lon=6.537046, lat=49.324550\n",
      "No suitable images found for location: lon=6.53705, lat=49.32455\n",
      "No suitable images found for location: lon=6.5370, lat=49.3245\n",
      "No suitable images found for location: lon=6.537, lat=49.325\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.537046193856699, lat=49.324549964905216\n",
      "No suitable images found for location: lon=2.057612, lat=48.238201\n",
      "No suitable images found for location: lon=2.05761, lat=48.23820\n",
      "No suitable images found for location: lon=2.0576, lat=48.2382\n",
      "No suitable images found for location: lon=2.058, lat=48.238\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=2.057611848951806, lat=48.23820078655202\n",
      "No suitable images found for location: lon=5.031798, lat=43.702803\n",
      "No suitable images found for location: lon=5.03180, lat=43.70280\n",
      "No suitable images found for location: lon=5.0318, lat=43.7028\n",
      "No suitable images found for location: lon=5.032, lat=43.703\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.031797583705215, lat=43.70280306843362\n",
      "No suitable images found for location: lon=0.015972, lat=49.261723\n",
      "No suitable images found for location: lon=0.01597, lat=49.26172\n",
      "No suitable images found for location: lon=0.0160, lat=49.2617\n",
      "No suitable images found for location: lon=0.016, lat=49.262\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=0.0159722731690883, lat=49.26172317768533\n",
      "No suitable images found for location: lon=5.425173, lat=45.570039\n",
      "No suitable images found for location: lon=5.42517, lat=45.57004\n",
      "No suitable images found for location: lon=5.4252, lat=45.5700\n",
      "No suitable images found for location: lon=5.425, lat=45.570\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.425173048518582, lat=45.57003864100367\n",
      "No suitable images found for location: lon=0.021575, lat=45.734841\n",
      "No suitable images found for location: lon=0.02157, lat=45.73484\n",
      "No suitable images found for location: lon=0.0216, lat=45.7348\n",
      "No suitable images found for location: lon=0.022, lat=45.735\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=0.0215746264345487, lat=45.73484118290455\n",
      "No suitable images found for location: lon=-0.683557, lat=44.740870\n",
      "No suitable images found for location: lon=-0.68356, lat=44.74087\n",
      "No suitable images found for location: lon=-0.6836, lat=44.7409\n",
      "No suitable images found for location: lon=-0.684, lat=44.741\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=-0.683557030025571, lat=44.74086988884957\n",
      "No suitable images found for location: lon=-3.205783, lat=48.824597\n",
      "No suitable images found for location: lon=-3.20578, lat=48.82460\n",
      "No suitable images found for location: lon=-3.2058, lat=48.8246\n",
      "No suitable images found for location: lon=-3.206, lat=48.825\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=-3.20578347535832, lat=48.824597209064834\n",
      "No suitable images found for location: lon=1.235345, lat=43.353489\n",
      "No suitable images found for location: lon=1.23535, lat=43.35349\n",
      "No suitable images found for location: lon=1.2353, lat=43.3535\n",
      "No suitable images found for location: lon=1.235, lat=43.353\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=1.2353451181221184, lat=43.353489156911095\n",
      "No suitable images found for location: lon=-1.543452, lat=43.483426\n",
      "No suitable images found for location: lon=-1.54345, lat=43.48343\n",
      "No suitable images found for location: lon=-1.5435, lat=43.4834\n",
      "No suitable images found for location: lon=-1.543, lat=43.483\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=-1.5434516197927304, lat=43.483426001613424\n",
      "No suitable images found for location: lon=-0.538007, lat=45.955775\n",
      "No suitable images found for location: lon=-0.53801, lat=45.95578\n",
      "No suitable images found for location: lon=-0.5380, lat=45.9558\n",
      "No suitable images found for location: lon=-0.538, lat=45.956\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=-0.5380071565185104, lat=45.955775194116335\n",
      "No suitable images found for location: lon=1.877818, lat=48.776690\n",
      "No suitable images found for location: lon=1.87782, lat=48.77669\n",
      "No suitable images found for location: lon=1.8778, lat=48.7767\n",
      "No suitable images found for location: lon=1.878, lat=48.777\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=1.8778183426128456, lat=48.77668969167733\n",
      "No suitable images found for location: lon=5.767443, lat=43.938999\n",
      "No suitable images found for location: lon=5.76744, lat=43.93900\n",
      "No suitable images found for location: lon=5.7674, lat=43.9390\n",
      "No suitable images found for location: lon=5.767, lat=43.939\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.767443382652005, lat=43.93899917292151\n",
      "No suitable images found for location: lon=-0.355335, lat=43.681114\n",
      "No suitable images found for location: lon=-0.35534, lat=43.68111\n",
      "No suitable images found for location: lon=-0.3553, lat=43.6811\n",
      "No suitable images found for location: lon=-0.355, lat=43.681\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=-0.3553351795329951, lat=43.68111444281003\n"
     ]
    }
   ],
   "source": [
    "# Assuming current_directory and processed_df_path are set from the previous code chunk\n",
    "print(f\"Images will be saved in: {current_directory}\")\n",
    "print(f\"Using kartaview_keys from: {processed_df_path}\")\n",
    "\n",
    "# Consistency check between image directory and kartaview_keys path\n",
    "expected_csv_map = {\n",
    "    '/workspace/workspace/ufo-prediction/image_data': '/workspace/workspace/ufo-prediction/demo/kartaview_key.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_NLD': '/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_FRA': '/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_ESP': '/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv',\n",
    "}\n",
    "\n",
    "# Stop the code if using image_data directory\n",
    "if current_directory == '/workspace/workspace/ufo-prediction/image_data':\n",
    "    print(\"Download for the 'image_data' directory has already been completed. Stopping execution.\")\n",
    "    # Use `exit()` or `sys.exit()` depending on your environment\n",
    "    exit()\n",
    "\n",
    "if processed_df_path != expected_csv_map.get(current_directory):\n",
    "    print(\"Inconsistency detected between the image directory and the kartaview_keys path. Please check.\")\n",
    "    exit()\n",
    "\n",
    "image_count = {} \n",
    "print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "\n",
    "#Initialise a counter for the loop iterations\n",
    "iteration_counter = 0\n",
    "\n",
    "for index, row in kartaview_keys.iterrows():\n",
    "    iteration_counter += 1 # Increment the counter with each iteration\n",
    "    precision = 6  # Start with 6 decimal places\n",
    "    success = False  # Flag to indicate if the request was successful\n",
    "\n",
    "    while precision > 2 and not success:\n",
    "        # Format lon and lat to the current precision\n",
    "        lon = f\"{row['lon']:.{precision}f}\"\n",
    "        lat = f\"{row['lat']:.{precision}f}\"\n",
    "\n",
    "        # Construct the API URL\n",
    "        url = \"https://api.openstreetcam.org/2.0/photo/?lat={}&lng={}\".format(lat, lon)\n",
    "\n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            url_pattern = r'https://storage\\d+\\.openstreetcam\\.org/files/photo/\\d+/\\d+/\\d+/[^\"]+\\.jpg'\n",
    "            urls = re.findall(url_pattern, json.dumps(data))\n",
    "\n",
    "            filtered_urls = [\n",
    "                url for url in urls\n",
    "                if not any(x in url.rsplit('/', 2)[-2] for x in [\"{{sizeprefix}}\", \"proc\"]) and\n",
    "                (\"th\" in url.rsplit('/', 2)[-2] and not \"lth\" in url.rsplit('/', 2)[-2])\n",
    "            ]\n",
    "\n",
    "            if filtered_urls:\n",
    "                # Initialize or update the image count for the current ID\n",
    "                building_id = row['id']  # Assuming 'id' column exists in your DataFrame\n",
    "                if building_id not in image_count:\n",
    "                    image_count[building_id] = 0\n",
    "\n",
    "                for image_url in filtered_urls:\n",
    "                    image_count[building_id] += 1  # Increment the image count for the building\n",
    "                    subscript = image_count[building_id]  # Subscript for the file name\n",
    "                    file_name = f\"{row['age_right']}_{building_id}_{subscript}.jpg\"\n",
    "                    file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "                    # Check if the file already exists\n",
    "                    if os.path.exists(file_path):\n",
    "                        print(f\"File already exists: {file_path}. Skipping download.\")\n",
    "                    else:\n",
    "                        image_response = requests.get(image_url)\n",
    "\n",
    "                        if image_response.status_code == 200:\n",
    "                            with open(file_path, 'wb') as f:\n",
    "                                f.write(image_response.content)\n",
    "                            print(\"Image downloaded successfully: {}\".format(file_path))\n",
    "                        else:\n",
    "                            print(\"Failed to download the image.\")\n",
    "                success = True  # Mark success as True to exit the while loop\n",
    "            else:\n",
    "                print(\"No suitable images found for location: lon={}, lat={}\".format(lon, lat))\n",
    "                precision -= 1  # Reduce precision by one decimal place\n",
    "        else:\n",
    "            print(\"Failed to retrieve data from the API for location: lon={}, lat={}. Trying with reduced precision.\")\n",
    "            \n",
    "\n",
    "    # After processing, remove the row from df_subset\n",
    "    kartaview_keys = kartaview_keys.drop(index)\n",
    "\n",
    "    # Only save the updated DataFrame to a CSV file every 100th instance\n",
    "    if iteration_counter % 100 == 0:\n",
    "        print(f\"Saving progress at iteration {iteration_counter} to {processed_df_path}. \")\n",
    "        print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "        kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "    if not success:\n",
    "        print(\"Unable to retrieve data from the API with sufficient precision for location: lon={}, lat={}\".format(row['lon'], row['lat']))\n",
    "        \n",
    "if iteration_counter % 100 != 0:\n",
    "    print(f\"Saving final progress\")\n",
    "    print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "    kartaview_keys.to_csv(processed_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
