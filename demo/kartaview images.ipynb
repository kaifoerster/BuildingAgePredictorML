{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos:\n",
    "- create a dataset with age and lon, lat and download it - CHECK\n",
    "- specify a new location to save images on the server -  CHECK\n",
    "- loop over the dataset - CHECK\n",
    " - plug in lat and lon into the api code below - CHECK\n",
    " - extract all images for that location - CHECK\n",
    " - name image according to age and its unique code after the last - CHECK\n",
    "\n",
    "CNN\n",
    "- rewatch simple CNN video how to extract age from name file - CHECK\n",
    "- run a simple CNN and compare results - CHECK\n",
    "- how to boost perfromance - HALF-CHECK - wait for reply from Nikola and start reading papers to do it yourself.\n",
    "- How to increase image quality and coverage? - HALF-CHECK - wait for Nikolas reply on a code basis, read other papers on how they implement it.\n",
    "\n",
    "Extent dataset:\n",
    "- access Mapillary data either through API or the download you did\n",
    "- repeat above excercise\n",
    "- compare R2\n",
    "- compare coverage of images between the two - are the duplicates?\n",
    "\n",
    "Integration\n",
    "- add a building ID to the kartaview key \n",
    "- Download images for buildings that do not have transaction data and train the algorithm on it\n",
    "- use the images that have transaction data as test set - CAREFUL THO DUE TO SELECTION ISSUES.\n",
    "- save the age predictions from this first step and add them as prediction variable into the matched GIS-RCA dataset as a variable using the building ID as key\n",
    "- rerun the xgboost model on it and see how it performs\n",
    "- in the best scenario, you can develop a multi-modal model that optimises the relational and image data together in one deep learning model, but this is REALLY OPTIONAL\n",
    "- OPTIONAL: Does it make sense to run a computer vision excercise to predict architectural style and feed that into the relational data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# project lib\n",
    "PROJECT_SRC_PATH = os.path.join( '/workspace/workspace/ufo-prediction', 'src-RCA-UFO')\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /workspace/workspace/ufo-prediction/image_data_FRA already exists.\n",
      "Loaded processed DataFrame from /workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv\n",
      "Empty DataFrame\n",
      "Columns: [lon, lat, age_right, id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)  # You can choose any number as your seed\n",
    "\n",
    "# Define paths for data\n",
    "path_data_NLD = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-NLD.pkl')\n",
    "path_data_FRA = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-FRA.pkl')\n",
    "path_data_ESP = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-ESP.pkl')\n",
    "processed_df_NLD = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv\"\n",
    "processed_df_ESP = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv\"\n",
    "processed_df_FRA = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv\"\n",
    "processed_df_ALL = \"/workspace/workspace/ufo-prediction/demo/kartaview_key.csv\"\n",
    "\n",
    "# Image directory paths\n",
    "image_dir_map = {\n",
    "    'NLD': '/workspace/workspace/ufo-prediction/image_data_NLD',\n",
    "    'FRA': '/workspace/workspace/ufo-prediction/image_data_FRA',\n",
    "    'ESP': '/workspace/workspace/ufo-prediction/image_data_ESP',\n",
    "    'ALL': '/workspace/workspace/ufo-prediction/image_data_ID'\n",
    "}\n",
    "\n",
    "# Ask for user input\n",
    "country_code = input(\"Enter country code (FRA, NLD, ESP) or ALL: \").upper()\n",
    "\n",
    "# Map user input to the correct path\n",
    "path_data_map = {\n",
    "    'NLD': processed_df_NLD,\n",
    "    'FRA': processed_df_FRA,\n",
    "    'ESP': processed_df_ESP,\n",
    "    'ALL': processed_df_ALL\n",
    "}\n",
    "\n",
    "raw_data_path_map = {\n",
    "'NLD': path_data_NLD,\n",
    "'FRA': path_data_FRA,\n",
    "'ESP': path_data_ESP\n",
    "}\n",
    "# Check if the input is valid\n",
    "if country_code not in path_data_map:\n",
    "    print(\"Invalid country code or specification. Please enter FRA, NLD, ESP, or ALL.\")\n",
    "else:\n",
    "    processed_df_path = path_data_map[country_code]\n",
    "    # Set directory based on country code\n",
    "    current_directory = image_dir_map[country_code]\n",
    "\n",
    "    # Check if the new directory exists, if not, create it\n",
    "    if not os.path.exists(current_directory):\n",
    "        os.makedirs(current_directory)\n",
    "        print(f\"Directory {current_directory} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {current_directory} already exists.\")\n",
    "\n",
    "    # Process for ALL\n",
    "    if country_code == 'ALL':\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(\"Creating a new processed DataFrame for ALL\")\n",
    "            path_data_RCA = os.path.join(dataset.DATA_DIR, 'rca-ufo-merge_ALL.csv')\n",
    "            df = pd.read_csv(path_data_RCA, encoding='latin1')\n",
    "            kartaview_keys = df[['lon', 'lat','age_right', 'id', 'PropertyKey_ID']]\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "            \n",
    "\n",
    "    # Process for FRA, NLD, ESP\n",
    "    else:\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(f\"Creating a new processed DataFrame for {country_code}\")\n",
    "            df_path = raw_data_path_map[country_code]\n",
    "            df = pd.read_pickle(df_path)\n",
    "            print(\"Loaded DataFrame from\", df_path)\n",
    "            sampled_df = df.sample(n=100000, random_state=42)\n",
    "            kartaview_keys = sampled_df[['lon', 'lat', 'age', 'id']].rename(columns={'age': 'age_right'})\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "print(kartaview_keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/workspace/ufo-prediction/image_data_FRA\n",
      "Empty DataFrame\n",
      "Columns: [lon, lat, age_right, id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(current_directory)\n",
    "print(kartaview_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be saved in: /workspace/workspace/ufo-prediction/image_data_FRA\n",
      "Using kartaview_keys from: /workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv\n",
      "Number of buildings remaining:  0\n"
     ]
    }
   ],
   "source": [
    "# Assuming current_directory and processed_df_path are set from the previous code chunk\n",
    "print(f\"Images will be saved in: {current_directory}\")\n",
    "print(f\"Using kartaview_keys from: {processed_df_path}\")\n",
    "\n",
    "# Consistency check between image directory and kartaview_keys path\n",
    "expected_csv_map = {\n",
    "    '/workspace/workspace/ufo-prediction/image_data_ID': '/workspace/workspace/ufo-prediction/demo/kartaview_key.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_NLD': '/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_FRA': '/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_ESP': '/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv',\n",
    "}\n",
    "\n",
    "# Stop the code if using image_data directory\n",
    "if current_directory == '/workspace/workspace/ufo-prediction/image_data':\n",
    "    print(\"Download for the 'image_data' directory has already been completed. Stopping execution.\")\n",
    "    # Use `exit()` or `sys.exit()` depending on your environment\n",
    "    exit()\n",
    "\n",
    "if processed_df_path != expected_csv_map.get(current_directory):\n",
    "    print(\"Inconsistency detected between the image directory and the kartaview_keys path. Please check.\")\n",
    "    exit()\n",
    "\n",
    "image_count = {} \n",
    "print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "\n",
    "for index, row in kartaview_keys.iterrows():\n",
    "    precision = 6  # Start with 6 decimal places\n",
    "    success = False  # Flag to indicate if the request was successful\n",
    "\n",
    "    while precision > 2 and not success:\n",
    "        # Format lon and lat to the current precision\n",
    "        lon = f\"{row['lon']:.{precision}f}\"\n",
    "        lat = f\"{row['lat']:.{precision}f}\"\n",
    "\n",
    "        # Construct the API URL\n",
    "        url = \"https://api.openstreetcam.org/2.0/photo/?lat={}&lng={}\".format(lat, lon)\n",
    "\n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            url_pattern = r'https://storage\\d+\\.openstreetcam\\.org/files/photo/\\d+/\\d+/\\d+/[^\"]+\\.jpg'\n",
    "            urls = re.findall(url_pattern, json.dumps(data))\n",
    "\n",
    "            filtered_urls = [\n",
    "                url for url in urls\n",
    "                if not any(x in url.rsplit('/', 2)[-2] for x in [\"{{sizeprefix}}\", \"proc\"]) and\n",
    "                (\"th\" in url.rsplit('/', 2)[-2] and not \"lth\" in url.rsplit('/', 2)[-2])\n",
    "            ]\n",
    "\n",
    "            if filtered_urls:\n",
    "                # Initialize or update the image count for the current ID\n",
    "                building_id = row['id']  # Assuming 'id' column exists in your DataFrame\n",
    "                if building_id not in image_count:\n",
    "                    image_count[building_id] = 0\n",
    "\n",
    "                for image_url in filtered_urls:\n",
    "                    image_count[building_id] += 1  # Increment the image count for the building\n",
    "                    subscript = image_count[building_id]  # Subscript for the file name\n",
    "                    file_name = f\"{row['age_right']}_{building_id}_{subscript}.jpg\"\n",
    "                    file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "                    # Check if the file already exists\n",
    "                    if os.path.exists(file_path):\n",
    "                        print(f\"File already exists: {file_path}. Skipping download.\")\n",
    "                    else:\n",
    "                        image_response = requests.get(image_url)\n",
    "\n",
    "                        if image_response.status_code == 200:\n",
    "                            with open(file_path, 'wb') as f:\n",
    "                                f.write(image_response.content)\n",
    "                            print(\"Image downloaded successfully: {}\".format(file_path))\n",
    "                        else:\n",
    "                            print(\"Failed to download the image.\")\n",
    "                success = True  # Mark success as True to exit the while loop\n",
    "            else:\n",
    "                print(\"No suitable images found for location: lon={}, lat={}\".format(lon, lat))\n",
    "                precision -= 1  # Reduce precision by one decimal place\n",
    "        else:\n",
    "            print(\"Failed to retrieve data from the API for location: lon={}, lat={}. Trying with reduced precision.\")\n",
    "            \n",
    "\n",
    "    # After processing, remove the row from df_subset\n",
    "    kartaview_keys = kartaview_keys.drop(index)\n",
    "\n",
    "    # Save the updated DataFrame to a CSV file\n",
    "    kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "    if not success:\n",
    "        print(\"Unable to retrieve data from the API with sufficient precision for location: lon={}, lat={}\".format(row['lon'], row['lat']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
