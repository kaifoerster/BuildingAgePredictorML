{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dos:\n",
    "- create a dataset with age and lon, lat and download it - CHECK\n",
    "- specify a new location to save images on the server -  CHECK\n",
    "- loop over the dataset - CHECK\n",
    " - plug in lat and lon into the api code below - CHECK\n",
    " - extract all images for that location - CHECK\n",
    " - name image according to age and its unique code after the last - CHECK\n",
    "\n",
    "CNN\n",
    "- rewatch simple CNN video how to extract age from name file - CHECK\n",
    "- run a simple CNN and compare results - CHECK\n",
    "- how to boost perfromance - HALF-CHECK - wait for reply from Nikola and start reading papers to do it yourself.\n",
    "- How to increase image quality and coverage? - HALF-CHECK - wait for Nikolas reply on a code basis, read other papers on how they implement it.\n",
    "\n",
    "Extent dataset:\n",
    "- access Mapillary data either through API or the download you did\n",
    "- repeat above excercise\n",
    "- compare R2\n",
    "- compare coverage of images between the two - are the duplicates?\n",
    "\n",
    "Integration\n",
    "- add a building ID to the kartaview key \n",
    "- Download images for buildings that do not have transaction data and train the algorithm on it\n",
    "- use the images that have transaction data as test set - CAREFUL THO DUE TO SELECTION ISSUES.\n",
    "- save the age predictions from this first step and add them as prediction variable into the matched GIS-RCA dataset as a variable using the building ID as key\n",
    "- rerun the xgboost model on it and see how it performs\n",
    "- in the best scenario, you can develop a multi-modal model that optimises the relational and image data together in one deep learning model, but this is REALLY OPTIONAL\n",
    "- OPTIONAL: Does it make sense to run a computer vision excercise to predict architectural style and feed that into the relational data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# project lib\n",
    "PROJECT_SRC_PATH = os.path.join( '/workspace/workspace/ufo-prediction', 'src-RCA-UFO')\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /workspace/workspace/ufo-prediction/image_data_NLD already exists.\n",
      "Loaded processed DataFrame from /workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv\n",
      "            lon        lat  age_right                      id\n",
      "0      4.797011  52.459691     1978.0   v0.1-NLD.9.62_1-78493\n",
      "1      4.591427  51.982949     2001.0  v0.1-NLD.14.67_1-35194\n",
      "2      5.134116  51.462842     1968.0    v0.1-NLD.8.34_1-6349\n",
      "3      4.959784  51.487404     1911.0     v0.1-NLD.8.3_1-6747\n",
      "4      5.388954  51.512629     1987.0     v0.1-NLD.8.9_1-8298\n",
      "...         ...        ...        ...                     ...\n",
      "85431  5.787166  51.682889     1935.0     v0.1-NLD.8.41_1-176\n",
      "85432  6.715116  52.105296     1980.0    v0.1-NLD.4.19_1-4362\n",
      "85433  6.904889  52.745651     1984.0    v0.1-NLD.1.6_1-23122\n",
      "85434  5.630706  53.043482     1989.0    v0.1-NLD.3.25_1-5671\n",
      "85435  5.668091  53.212675     1974.0    v0.1-NLD.3.18_1-9292\n",
      "\n",
      "[85436 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)  # You can choose any number as your seed\n",
    "\n",
    "# Define paths for data\n",
    "path_data_NLD = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-NLD.pkl')\n",
    "path_data_FRA = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-FRA.pkl')\n",
    "path_data_ESP = os.path.join('/workspace/workspace/ufo-prediction', 'demo', 'df-ESP.pkl')\n",
    "processed_df_NLD = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv\"\n",
    "processed_df_ESP = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv\"\n",
    "processed_df_FRA = \"/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv\"\n",
    "processed_df_ALL = \"/workspace/workspace/ufo-prediction/demo/kartaview_key.csv\"\n",
    "\n",
    "# Image directory paths\n",
    "image_dir_map = {\n",
    "    'NLD': '/workspace/workspace/ufo-prediction/image_data_NLD',\n",
    "    'FRA': '/workspace/workspace/ufo-prediction/image_data_FRA',\n",
    "    'ESP': '/workspace/workspace/ufo-prediction/image_data_ESP',\n",
    "    'ALL': '/workspace/workspace/ufo-prediction/image_data'\n",
    "}\n",
    "\n",
    "# Ask for user input\n",
    "country_code = input(\"Enter country code (FRA, NLD, ESP) or ALL: \").upper()\n",
    "\n",
    "# Map user input to the correct path\n",
    "path_data_map = {\n",
    "    'NLD': processed_df_NLD,\n",
    "    'FRA': processed_df_FRA,\n",
    "    'ESP': processed_df_ESP,\n",
    "    'ALL': processed_df_ALL\n",
    "}\n",
    "\n",
    "raw_data_path_map = {\n",
    "'NLD': path_data_NLD,\n",
    "'FRA': path_data_FRA,\n",
    "'ESP': path_data_ESP\n",
    "}\n",
    "# Check if the input is valid\n",
    "if country_code not in path_data_map:\n",
    "    print(\"Invalid country code or specification. Please enter FRA, NLD, ESP, or ALL.\")\n",
    "else:\n",
    "    processed_df_path = path_data_map[country_code]\n",
    "    # Set directory based on country code\n",
    "    current_directory = image_dir_map[country_code]\n",
    "\n",
    "    # Check if the new directory exists, if not, create it\n",
    "    if not os.path.exists(current_directory):\n",
    "        os.makedirs(current_directory)\n",
    "        print(f\"Directory {current_directory} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {current_directory} already exists.\")\n",
    "\n",
    "    # Process for ALL\n",
    "    if country_code == 'ALL':\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(\"Creating a new processed DataFrame for ALL\")\n",
    "            path_data_RCA = os.path.join(dataset.DATA_DIR, 'rca-ufo-merge_ALL.csv')\n",
    "            df = pd.read_csv(path_data_RCA, encoding='latin1')\n",
    "            kartaview_keys = df[['lon', 'lat','age_right', 'id', 'PropertyKey_ID']]\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "            \n",
    "\n",
    "    # Process for FRA, NLD, ESP\n",
    "    else:\n",
    "        if os.path.exists(processed_df_path):\n",
    "            kartaview_keys = pd.read_csv(processed_df_path)\n",
    "            print(\"Loaded processed DataFrame from\", processed_df_path)\n",
    "        else:\n",
    "            print(f\"Creating a new processed DataFrame for {country_code}\")\n",
    "            df_path = raw_data_path_map[country_code]\n",
    "            df = pd.read_pickle(df_path)\n",
    "            print(\"Loaded DataFrame from\", df_path)\n",
    "            sampled_df = df.sample(n=100000, random_state=42)\n",
    "            kartaview_keys = sampled_df[['lon', 'lat', 'age', 'id']].rename(columns={'age': 'age_right'})\n",
    "            kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "print(kartaview_keys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/workspace/ufo-prediction/image_data_NLD\n",
      "            lon        lat  age_right                      id\n",
      "0      4.797011  52.459691     1978.0   v0.1-NLD.9.62_1-78493\n",
      "1      4.591427  51.982949     2001.0  v0.1-NLD.14.67_1-35194\n",
      "2      5.134116  51.462842     1968.0    v0.1-NLD.8.34_1-6349\n",
      "3      4.959784  51.487404     1911.0     v0.1-NLD.8.3_1-6747\n",
      "4      5.388954  51.512629     1987.0     v0.1-NLD.8.9_1-8298\n",
      "...         ...        ...        ...                     ...\n",
      "85431  5.787166  51.682889     1935.0     v0.1-NLD.8.41_1-176\n",
      "85432  6.715116  52.105296     1980.0    v0.1-NLD.4.19_1-4362\n",
      "85433  6.904889  52.745651     1984.0    v0.1-NLD.1.6_1-23122\n",
      "85434  5.630706  53.043482     1989.0    v0.1-NLD.3.25_1-5671\n",
      "85435  5.668091  53.212675     1974.0    v0.1-NLD.3.18_1-9292\n",
      "\n",
      "[85436 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(current_directory)\n",
    "print(kartaview_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be saved in: /workspace/workspace/ufo-prediction/image_data_NLD\n",
      "Using kartaview_keys from: /workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv\n",
      "Number of buildings remaining:  85436\n",
      "No suitable images found for location: lon=4.797011, lat=52.459691\n",
      "No suitable images found for location: lon=4.79701, lat=52.45969\n",
      "No suitable images found for location: lon=4.7970, lat=52.4597\n",
      "No suitable images found for location: lon=4.797, lat=52.460\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.797010965186524, lat=52.45969101989579\n",
      "No suitable images found for location: lon=4.591427, lat=51.982949\n",
      "No suitable images found for location: lon=4.59143, lat=51.98295\n",
      "No suitable images found for location: lon=4.5914, lat=51.9829\n",
      "No suitable images found for location: lon=4.591, lat=51.983\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.591426837217772, lat=51.98294872327365\n",
      "No suitable images found for location: lon=5.134116, lat=51.462842\n",
      "No suitable images found for location: lon=5.13412, lat=51.46284\n",
      "No suitable images found for location: lon=5.1341, lat=51.4628\n",
      "No suitable images found for location: lon=5.134, lat=51.463\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.134116447716389, lat=51.4628416888261\n",
      "No suitable images found for location: lon=4.959784, lat=51.487404\n",
      "No suitable images found for location: lon=4.95978, lat=51.48740\n",
      "No suitable images found for location: lon=4.9598, lat=51.4874\n",
      "No suitable images found for location: lon=4.960, lat=51.487\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.9597841459697545, lat=51.48740419720282\n",
      "No suitable images found for location: lon=5.388954, lat=51.512629\n",
      "No suitable images found for location: lon=5.38895, lat=51.51263\n",
      "No suitable images found for location: lon=5.3890, lat=51.5126\n",
      "No suitable images found for location: lon=5.389, lat=51.513\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.388954105603868, lat=51.51262860880892\n",
      "No suitable images found for location: lon=5.855683, lat=51.826970\n",
      "No suitable images found for location: lon=5.85568, lat=51.82697\n",
      "No suitable images found for location: lon=5.8557, lat=51.8270\n",
      "No suitable images found for location: lon=5.856, lat=51.827\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.85568276724574, lat=51.8269697556581\n",
      "No suitable images found for location: lon=4.745410, lat=52.234820\n",
      "No suitable images found for location: lon=4.74541, lat=52.23482\n",
      "No suitable images found for location: lon=4.7454, lat=52.2348\n",
      "No suitable images found for location: lon=4.745, lat=52.235\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.745410001948464, lat=52.23482001943351\n",
      "No suitable images found for location: lon=6.398962, lat=53.252601\n",
      "No suitable images found for location: lon=6.39896, lat=53.25260\n",
      "No suitable images found for location: lon=6.3990, lat=53.2526\n",
      "No suitable images found for location: lon=6.399, lat=53.253\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.39896203912256, lat=53.252601129680535\n",
      "No suitable images found for location: lon=6.060379, lat=53.086299\n",
      "No suitable images found for location: lon=6.06038, lat=53.08630\n",
      "No suitable images found for location: lon=6.0604, lat=53.0863\n",
      "No suitable images found for location: lon=6.060, lat=53.086\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.0603792627072215, lat=53.08629906185936\n",
      "No suitable images found for location: lon=6.878436, lat=52.207391\n",
      "No suitable images found for location: lon=6.87844, lat=52.20739\n",
      "No suitable images found for location: lon=6.8784, lat=52.2074\n",
      "Image downloaded successfully: /workspace/workspace/ufo-prediction/image_data_NLD/1967.0_v0.1-NLD.10.7_1-49150_1.jpg\n",
      "No suitable images found for location: lon=4.758889, lat=53.092030\n",
      "No suitable images found for location: lon=4.75889, lat=53.09203\n",
      "No suitable images found for location: lon=4.7589, lat=53.0920\n",
      "No suitable images found for location: lon=4.759, lat=53.092\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.7588891197120855, lat=53.09202956158452\n",
      "No suitable images found for location: lon=5.680440, lat=53.041825\n",
      "No suitable images found for location: lon=5.68044, lat=53.04183\n",
      "No suitable images found for location: lon=5.6804, lat=53.0418\n",
      "No suitable images found for location: lon=5.680, lat=53.042\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.680440107239742, lat=53.04182503913628\n",
      "No suitable images found for location: lon=5.046981, lat=52.018510\n",
      "No suitable images found for location: lon=5.04698, lat=52.01851\n",
      "No suitable images found for location: lon=5.0470, lat=52.0185\n",
      "No suitable images found for location: lon=5.047, lat=52.019\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.046980605087548, lat=52.01851021755663\n",
      "No suitable images found for location: lon=6.173853, lat=52.263995\n",
      "No suitable images found for location: lon=6.17385, lat=52.26399\n",
      "No suitable images found for location: lon=6.1739, lat=52.2640\n",
      "No suitable images found for location: lon=6.174, lat=52.264\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.1738531277350335, lat=52.2639949504314\n",
      "No suitable images found for location: lon=6.132779, lat=51.334945\n",
      "No suitable images found for location: lon=6.13278, lat=51.33494\n",
      "No suitable images found for location: lon=6.1328, lat=51.3349\n",
      "No suitable images found for location: lon=6.133, lat=51.335\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=6.132779487993752, lat=51.334944638881765\n",
      "No suitable images found for location: lon=5.937809, lat=52.186171\n",
      "No suitable images found for location: lon=5.93781, lat=52.18617\n",
      "No suitable images found for location: lon=5.9378, lat=52.1862\n",
      "No suitable images found for location: lon=5.938, lat=52.186\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.937808718896051, lat=52.18617067205729\n",
      "No suitable images found for location: lon=4.919221, lat=51.591959\n",
      "No suitable images found for location: lon=4.91922, lat=51.59196\n",
      "No suitable images found for location: lon=4.9192, lat=51.5920\n",
      "No suitable images found for location: lon=4.919, lat=51.592\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.919220622316755, lat=51.59195914155282\n",
      "No suitable images found for location: lon=4.997436, lat=52.668794\n",
      "No suitable images found for location: lon=4.99744, lat=52.66879\n",
      "No suitable images found for location: lon=4.9974, lat=52.6688\n",
      "No suitable images found for location: lon=4.997, lat=52.669\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=4.997436049662626, lat=52.668794213201934\n",
      "No suitable images found for location: lon=5.763485, lat=52.709625\n",
      "No suitable images found for location: lon=5.76348, lat=52.70962\n",
      "No suitable images found for location: lon=5.7635, lat=52.7096\n",
      "No suitable images found for location: lon=5.763, lat=52.710\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.763484512295717, lat=52.70962476249534\n",
      "No suitable images found for location: lon=5.434993, lat=51.806623\n",
      "No suitable images found for location: lon=5.43499, lat=51.80662\n",
      "No suitable images found for location: lon=5.4350, lat=51.8066\n",
      "No suitable images found for location: lon=5.435, lat=51.807\n",
      "Unable to retrieve data from the API with sufficient precision for location: lon=5.4349934852122805, lat=51.806622512449145\n",
      "No suitable images found for location: lon=6.715483, lat=51.980063\n",
      "No suitable images found for location: lon=6.71548, lat=51.98006\n",
      "No suitable images found for location: lon=6.7155, lat=51.9801\n"
     ]
    }
   ],
   "source": [
    "# Assuming current_directory and processed_df_path are set from the previous code chunk\n",
    "print(f\"Images will be saved in: {current_directory}\")\n",
    "print(f\"Using kartaview_keys from: {processed_df_path}\")\n",
    "\n",
    "# Consistency check between image directory and kartaview_keys path\n",
    "expected_csv_map = {\n",
    "    '/workspace/workspace/ufo-prediction/image_data': '/workspace/workspace/ufo-prediction/demo/kartaview_key.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_NLD': '/workspace/workspace/ufo-prediction/demo/kartaview_key_NLD.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_FRA': '/workspace/workspace/ufo-prediction/demo/kartaview_key_FRA.csv',\n",
    "    '/workspace/workspace/ufo-prediction/image_data_ESP': '/workspace/workspace/ufo-prediction/demo/kartaview_key_ESP.csv',\n",
    "}\n",
    "\n",
    "# Stop the code if using image_data directory\n",
    "if current_directory == '/workspace/workspace/ufo-prediction/image_data':\n",
    "    print(\"Download for the 'image_data' directory has already been completed. Stopping execution.\")\n",
    "    # Use `exit()` or `sys.exit()` depending on your environment\n",
    "    exit()\n",
    "\n",
    "if processed_df_path != expected_csv_map.get(current_directory):\n",
    "    print(\"Inconsistency detected between the image directory and the kartaview_keys path. Please check.\")\n",
    "    exit()\n",
    "\n",
    "image_count = {} \n",
    "print(\"Number of buildings remaining: \",len(kartaview_keys))\n",
    "\n",
    "for index, row in kartaview_keys.iterrows():\n",
    "    precision = 6  # Start with 6 decimal places\n",
    "    success = False  # Flag to indicate if the request was successful\n",
    "\n",
    "    while precision > 2 and not success:\n",
    "        # Format lon and lat to the current precision\n",
    "        lon = f\"{row['lon']:.{precision}f}\"\n",
    "        lat = f\"{row['lat']:.{precision}f}\"\n",
    "\n",
    "        # Construct the API URL\n",
    "        url = \"https://api.openstreetcam.org/2.0/photo/?lat={}&lng={}\".format(lat, lon)\n",
    "\n",
    "        # Send a GET request to the API\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            url_pattern = r'https://storage\\d+\\.openstreetcam\\.org/files/photo/\\d+/\\d+/\\d+/[^\"]+\\.jpg'\n",
    "            urls = re.findall(url_pattern, json.dumps(data))\n",
    "\n",
    "            filtered_urls = [\n",
    "                url for url in urls\n",
    "                if not any(x in url.rsplit('/', 2)[-2] for x in [\"{{sizeprefix}}\", \"proc\"]) and\n",
    "                (\"th\" in url.rsplit('/', 2)[-2] and not \"lth\" in url.rsplit('/', 2)[-2])\n",
    "            ]\n",
    "\n",
    "            if filtered_urls:\n",
    "                # Initialize or update the image count for the current ID\n",
    "                building_id = row['id']  # Assuming 'id' column exists in your DataFrame\n",
    "                if building_id not in image_count:\n",
    "                    image_count[building_id] = 0\n",
    "\n",
    "                for image_url in filtered_urls:\n",
    "                    image_count[building_id] += 1  # Increment the image count for the building\n",
    "                    subscript = image_count[building_id]  # Subscript for the file name\n",
    "                    file_name = f\"{row['age_right']}_{building_id}_{subscript}.jpg\"\n",
    "                    file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "                    # Check if the file already exists\n",
    "                    if os.path.exists(file_path):\n",
    "                        print(f\"File already exists: {file_path}. Skipping download.\")\n",
    "                    else:\n",
    "                        image_response = requests.get(image_url)\n",
    "\n",
    "                        if image_response.status_code == 200:\n",
    "                            with open(file_path, 'wb') as f:\n",
    "                                f.write(image_response.content)\n",
    "                            print(\"Image downloaded successfully: {}\".format(file_path))\n",
    "                        else:\n",
    "                            print(\"Failed to download the image.\")\n",
    "                success = True  # Mark success as True to exit the while loop\n",
    "            else:\n",
    "                print(\"No suitable images found for location: lon={}, lat={}\".format(lon, lat))\n",
    "                precision -= 1  # Reduce precision by one decimal place\n",
    "        else:\n",
    "            print(\"Failed to retrieve data from the API for location: lon={}, lat={}. Trying with reduced precision.\")\n",
    "            \n",
    "\n",
    "    # After processing, remove the row from df_subset\n",
    "    kartaview_keys = kartaview_keys.drop(index)\n",
    "\n",
    "    # Save the updated DataFrame to a CSV file\n",
    "    kartaview_keys.to_csv(processed_df_path, index=False)\n",
    "\n",
    "    if not success:\n",
    "        print(\"Unable to retrieve data from the API with sufficient precision for location: lon={}, lat={}\".format(row['lon'], row['lat']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
