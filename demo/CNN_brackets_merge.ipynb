{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up packages and server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the GPU\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = 'your/own/cache/directory'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# Model training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import copy\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import lightning as L\n",
    "# from lightning import Trainer\n",
    "# from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Others\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# project lib\n",
    "PROJECT_SRC_PATH = os.path.join( '/workspace/workspace/ufo-prediction', 'src-RCA-UFO')\n",
    "sys.path.append(PROJECT_SRC_PATH)\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "GPU: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "# Check is GPU is enabled\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# Get specific GPU model\n",
    "if str(device) == \"cuda:0\":\n",
    "  print(\"GPU: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and preprocess the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [\n",
    "    Path('/workspace/workspace/ufo-prediction/image_data_NLD'),\n",
    "    Path('/workspace/workspace/ufo-prediction/image_data_ESP'),  # Add your second directory path here\n",
    "    Path('/workspace/workspace/ufo-prediction/image_data_FRA')   # Add your third directory path here\n",
    "]\n",
    "\n",
    "filepaths = pd.Series(\n",
    "    [item for directory in directories for item in directory.glob('**/*.jpg')],\n",
    "    name='Filepath'\n",
    ").astype(str)\n",
    "\n",
    "def get_age_bracket(age):\n",
    "    if 1900 <= age <= 1924:\n",
    "        return '1900-1924'\n",
    "    elif 1925 <= age <= 1945:\n",
    "        return '1925-1945'\n",
    "    elif 1946 <= age <= 1959:\n",
    "        return '1946-1959'\n",
    "    elif 1960 <= age <= 1969:\n",
    "        return '1960-1969'\n",
    "    elif 1970 <= age <= 1984:\n",
    "        return '1970-1984'\n",
    "    elif 1985 <= age <= 1999:\n",
    "        return '1985-1999'\n",
    "    elif 2000 <= age <= 2050:\n",
    "        return '2000-2050'\n",
    "    else:\n",
    "        return 'Unknown'  # For ages outside the specified brackets or if age couldn't be determined\n",
    "\n",
    "\n",
    "def extract_age_and_name(filepath):\n",
    "    filename = os.path.basename(filepath)  # Get the filename from the filepath\n",
    "    age_and_name = filename.split('.')[0]  # Split by dot and take the first part\n",
    "    age = ''.join(filter(str.isdigit, age_and_name))[:4]  # Extract first 4 digits for age\n",
    "    if age:  # Ensure age string is not empty\n",
    "        age = int(age)\n",
    "        age_bracket = get_age_bracket(age)  # Get the age bracket\n",
    "    else:  # Default age if no digits found\n",
    "        age_bracket = 'Unknown'\n",
    "    return age_bracket\n",
    "\n",
    "age_bracket_to_int = {\n",
    "    '1900-1924': 0,\n",
    "    '1925-1945': 1,\n",
    "    '1946-1959': 2,\n",
    "    '1960-1969': 3,\n",
    "    '1970-1984': 4,\n",
    "    '1985-1999': 5,\n",
    "    '2000-2050': 6\n",
    "}\n",
    "\n",
    "age_brackets = pd.Series(filepaths.apply(lambda x: extract_age_and_name(x)), name='Age Brackets')\n",
    "filtered_age_brackets = age_brackets[age_brackets != 'Unknown']\n",
    "filtered_filepaths = filepaths[age_brackets != 'Unknown']\n",
    "trainval_df = pd.concat([filtered_filepaths, filtered_age_brackets], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "trainval_df['Target'] = trainval_df['Age Brackets'].map(age_bracket_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(trainval_df, train_size=0.7, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeBracketDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.dataframe.iloc[idx, 2])  # Assuming the label/target is in the third column\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # ResNet-18 expects 224x224 inputs\n",
    "    transforms.RandomHorizontalFlip(),  # A common form of augmentation\n",
    "    #transforms.RandomRotation(15),  # Rotates the image by up to 15 degrees\n",
    "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Randomly jitters color\n",
    "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalization\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = AgeBracketDataset(train_df, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "val_dataset = AgeBracketDataset(val_df, transform=val_test_transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_val_loss(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=500, patience=15):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_val_loss = float('inf')  # Initialize the best validation loss as infinity\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training phase\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader):.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        scheduler.step(avg_val_loss)  # Learning rate scheduler step based on validation loss\n",
    "\n",
    "        # Check for improvement based on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs.')\n",
    "            early_stop = True\n",
    "            break\n",
    "    \n",
    "    if not early_stop:\n",
    "        print('Reached maximum epoch limit.')\n",
    "\n",
    "    # Load best model weights based on lowest validation loss\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return best_val_loss  # Return the best validation loss achieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Training Loss: 2.2131, Validation Loss: 1.9389\n",
      "Epoch 2/500, Training Loss: 1.8564, Validation Loss: 1.8455\n",
      "Epoch 3/500, Training Loss: 1.8115, Validation Loss: 1.8052\n",
      "Epoch 4/500, Training Loss: 1.7747, Validation Loss: 1.7679\n",
      "Epoch 5/500, Training Loss: 1.7225, Validation Loss: 1.8539\n",
      "Epoch 6/500, Training Loss: 1.6911, Validation Loss: 1.8452\n",
      "Epoch 7/500, Training Loss: 1.6641, Validation Loss: 1.7844\n",
      "Epoch 8/500, Training Loss: 1.6214, Validation Loss: 1.7219\n",
      "Epoch 9/500, Training Loss: 1.5877, Validation Loss: 1.7796\n",
      "Epoch 10/500, Training Loss: 1.5401, Validation Loss: 1.8158\n",
      "Epoch 11/500, Training Loss: 1.4968, Validation Loss: 1.8159\n",
      "Epoch 12/500, Training Loss: 1.4594, Validation Loss: 1.8080\n",
      "Epoch 13/500, Training Loss: 1.4168, Validation Loss: 1.8369\n",
      "Epoch 14/500, Training Loss: 1.3802, Validation Loss: 1.8066\n",
      "Epoch    14: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 15/500, Training Loss: 1.1985, Validation Loss: 1.8921\n",
      "Epoch 16/500, Training Loss: 1.1416, Validation Loss: 1.9070\n",
      "Epoch 17/500, Training Loss: 1.0938, Validation Loss: 2.0008\n",
      "Epoch 18/500, Training Loss: 1.0692, Validation Loss: 1.9342\n",
      "Epoch 19/500, Training Loss: 1.0592, Validation Loss: 1.9894\n",
      "Epoch 20/500, Training Loss: 1.0362, Validation Loss: 1.9960\n",
      "Epoch    20: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 21/500, Training Loss: 1.0027, Validation Loss: 2.0216\n",
      "Epoch 22/500, Training Loss: 0.9959, Validation Loss: 2.0525\n",
      "Epoch 23/500, Training Loss: 0.9959, Validation Loss: 2.0535\n",
      "Early stopping triggered after 23 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.721909741710003"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Best Parameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "unfreeze_option = 'last_plus_one'\n",
    "\n",
    "# Initialize the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the selected layers\n",
    "if unfreeze_option == 'last':\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "elif unfreeze_option == 'last_plus_one':\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Setup DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Setup optimizer, criterion, and scheduler\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Train the model\n",
    "train_and_evaluate_val_loss(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs=500, patience=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('/workspace/workspace/ufo-prediction/image_data_ID')\n",
    "\n",
    "filepaths = pd.Series(list(directory.glob(r'**/*.jpg')), name='Filepath').astype(str)\n",
    "age_brackets = pd.Series(filepaths.apply(lambda x: extract_age_and_name(x)), name='Age Brackets')\n",
    "filtered_age_brackets = age_brackets[age_brackets != 'Unknown']\n",
    "filtered_filepaths = filepaths[age_brackets != 'Unknown']\n",
    "\n",
    "test_df = pd.concat([filtered_filepaths, filtered_age_brackets], axis=1).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "test_df['Target'] = test_df['Age Brackets'].map(age_bracket_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Assuming test_df is your DataFrame\n",
    "test_dataset = CustomDataset(dataframe=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Infer age brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "predictions = []\n",
    "file_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, paths in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        file_paths.extend(paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Concatenate Building ID and use to merge to rca-ufo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_RCA = os.path.join(dataset.DATA_DIR, 'rca-ufo-merge_ALL.csv')\n",
    "df = pd.read_csv(path_data_RCA, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_building_id(filepath):\n",
    "    \"\"\"\n",
    "    Extracts the building ID from the given filepath string.\n",
    "    Knowing that the building ID always contains an underscore and considering the filename\n",
    "    format '[age_right]_[building_id]_[subscript].jpg', this function returns the 'building_id'.\n",
    "    \"\"\"\n",
    "    # Isolate the filename from the filepath\n",
    "    filename = filepath.split('/')[-1]\n",
    "    # Split the filename at underscores\n",
    "    parts = filename.split('_')\n",
    "    # Considering the first part is age_right and the last part is the subscript with .jpg,\n",
    "    # the building ID is everything in between.\n",
    "    # Rejoin the middle parts to account for underscores within the building ID itself.\n",
    "    building_id = '_'.join(parts[1:-1])\n",
    "    return building_id\n",
    "\n",
    "# Use the updated function to extract building IDs from file paths\n",
    "building_ids = [extract_building_id(path) for path in file_paths]\n",
    "\n",
    "# Prepare the predictions DataFrame with the correct building IDs\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': building_ids,\n",
    "    'CNN_age_bracket': predictions  # Or map to your age bracket strings if needed\n",
    "})\n",
    "\n",
    "# Now, predictions_df contains the correct Building IDs and their corresponding predicted age brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.merge(df, predictions_df, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('/workspace/workspace/ufo-prediction/demo/rca-ufo-CNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufo-predict2 (Tensorflow 2.11.0)",
   "language": "python",
   "name": "kai-ufo-predict2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
